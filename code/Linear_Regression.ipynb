{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Linear Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Splitting Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('slice_localization_data.csv')\n",
    "\n",
    "df_filled = df.fillna(df.mode().iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping off unnecessary variable ‘patientId’, separating features and target variables.\n",
    "\n",
    "df_copy = df_filled.drop(['patientId'], axis=1)\n",
    "df_y = df_copy['reference']\n",
    "df_x = df_copy.drop(['reference'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_x, df_y, test_size=0.3, random_state=42)\n",
    "\n",
    "# View the split data\n",
    "print(\"X_train:\")\n",
    "print(X_train.head())\n",
    "print(\"\\nX_test:\")\n",
    "print(X_test.head())\n",
    "print(\"\\ny_train:\")\n",
    "print(y_train.head())\n",
    "print(\"\\ny_test:\")\n",
    "print(y_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Apply Linear Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error,r2_score\n",
    "\n",
    "#for test dataset\n",
    "\n",
    "y_pred = lm.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print('Mean Squared Error:', mse)\n",
    "print('Mean Absolute Error:', mae)\n",
    "print('R-squared:', r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for training dataset\n",
    "\n",
    "y_pred = lm.predict(X_train)\n",
    "\n",
    "mse = mean_squared_error(y_train, y_pred)\n",
    "mae = mean_absolute_error(y_train, y_pred)\n",
    "r2 = r2_score(y_train, y_pred)\n",
    "\n",
    "print('Mean Squared Error:', mse)\n",
    "print('Mean Absolute Error:', mae)\n",
    "print('R-squared:', r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error,r2_score\n",
    "# Define the function to plot learning curves\n",
    "def plotLearningCurves(X, y, step):\n",
    "    m, n = X.shape\n",
    "    maxVal = (int)(m / 10) * 10\n",
    "    N_size_arr = np.arange(10, maxVal + 10, step)\n",
    "    error_arr = np.zeros((len(N_size_arr), 2))  # Updated line\n",
    "    index = 0\n",
    "\n",
    "    # Fitting Model\n",
    "    lm.fit(X, y)\n",
    "\n",
    "    # Increasing train dataset size, \"step\" times in each iteration\n",
    "    for i in N_size_arr:\n",
    "        # Splitting Training dataset with size i into train and cross-validation sets\n",
    "        X_train_subset = X_train[:i]\n",
    "        y_train_subset = y_train[:i]\n",
    "\n",
    "        # Computing both mean squared error of the training dataset and cross-validation datasets predictions\n",
    "        error_arr[index, 0] = mean_squared_error(y_train_subset, lm.predict(X_train_subset))\n",
    "        error_arr[index, 1] = mean_squared_error(y_test, lm.predict(X_test))\n",
    "\n",
    "        # Increasing index by 1\n",
    "        index += 1\n",
    "\n",
    "    # Initializing the figure\n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    ax = fig.add_axes([0, 0, 1, 1])\n",
    "    ax.set_yscale('log')\n",
    "\n",
    "    # Plotting \"Training set size\" vs. \"Mean Squared Error\" for both the training and cross-validation dataset's errors\n",
    "    line1, = ax.plot(N_size_arr, error_arr[:, 0], c='red')\n",
    "    line2, = ax.plot(N_size_arr, error_arr[:, 1], c='blue')\n",
    "\n",
    "    # Adding labels and legends to our plot\n",
    "    ax.set_xlabel(\"N (Training set size)\")\n",
    "    ax.set_ylabel(\"Mean Squared Error\")\n",
    "\n",
    "    ax.legend((line1, line2), (\"Train Error\", \"Test Error\"))\n",
    "\n",
    "# Call the function to plot the learning curves\n",
    "plotLearningCurves(X_train, y_train, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecting Reference values with the test dataset\n",
    "y_pred = lm.predict(X_test)\n",
    "\n",
    "# Plotting predictions vs. y_test\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = fig.add_axes([0, 0, 1, 1])\n",
    "\n",
    "ax.set_xlabel(\"Predictions\")\n",
    "ax.set_ylabel(\"Test Target Variable\")\n",
    "ax.plot(y_test, y_pred, 'bo', ms=1)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above information, it appears that the model might be slightly overfitting. Overfitting occurs when a model learns the training data too well and performs poorly on unseen data.\n",
    "\n",
    "The mean squared error (MSE) and mean absolute error (MAE) on the training dataset are slightly lower than on the test dataset. Additionally, the R-squared value on the training dataset is higher than on the test dataset.\n",
    "\n",
    "High complexity model: Overfitting can occur when the model is too complex relative to the available data. With a large number of features (386) compared to the number of instances (53500), it's possible that the model has learned noise or irrelevant patterns in the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
